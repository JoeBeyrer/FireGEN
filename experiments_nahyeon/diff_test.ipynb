{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models import *\n",
    "from loss import *\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../next_day_fires/next_day_wildfire_spread_train*'\n",
    "val_path = '../next_day_fires/next_day_wildfire_spread_eval*'\n",
    "test_path = '../next_day_fires/next_day_wildfire_spread_test*'\n",
    "features = ['elevation', 'th', 'vs',  'tmmn', 'tmmx', 'sph', 'pr', 'pdsi', 'NDVI', 'population', 'erc', 'PrevFireMask', 'FireMask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 12, 32, 32])\n",
      "torch.Size([100, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_dataset(\n",
    "      train_path,\n",
    "      data_size=64,\n",
    "      sample_size=32,\n",
    "      batch_size=100,\n",
    "      num_in_channels=12,\n",
    "      compression_type=None,\n",
    "      clip_and_normalize=False,\n",
    "      clip_and_rescale=False,\n",
    "      random_crop=True,\n",
    "      center_crop=False)\n",
    "\n",
    "train_inputs, train_labels = next(iter(train_dataset))\n",
    "\n",
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\n",
    "  'Elevation',\n",
    "  'Wind\\ndirection',\n",
    "  'Wind\\nvelocity',\n",
    "  'Min\\ntemp',\n",
    "  'Max\\ntemp',\n",
    "  'Humidity',\n",
    "  'Precip',\n",
    "  'Drought',\n",
    "  'Vegetation',\n",
    "  'Population\\ndensity',\n",
    "  'Energy\\nrelease\\ncomponent',\n",
    "  'Previous\\nfire\\nmask',\n",
    "  'Fire\\nmask'\n",
    "]\n",
    "\n",
    "n_rows = 5\n",
    "n_features = train_inputs.shape[3] \n",
    "CMAP = colors.ListedColormap(['black', 'silver', 'orangered'])\n",
    "BOUNDS = [-1, -0.1, 0.001, 1]\n",
    "NORM = colors.BoundaryNorm(BOUNDS, CMAP.N)\n",
    "keys = ['elevation', 'th', 'vs',  'tmmn', 'tmmx', 'sph', 'pr', 'pdsi', 'NDVI', 'population', 'erc', 'PrevFireMask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "# for i in range(n_rows):\n",
    "#   for j in range(n_features + 1):\n",
    "#     plt.subplot(n_rows, n_features + 1, i * (n_features + 1) + j + 1)\n",
    "#     if i == 0:\n",
    "#       plt.title(titles[j], fontsize=15)\n",
    "#     if j < n_features - 1:\n",
    "#       plt.imshow(train_inputs[i, j, :, :], cmap='viridis')\n",
    "#     if j == n_features - 1:\n",
    "#       plt.imshow(train_inputs[i, -1, :, :], cmap=CMAP, norm=NORM)\n",
    "#     if j == n_features:\n",
    "#       plt.imshow(train_labels[i, 0, :, :], cmap=CMAP, norm=NORM) \n",
    "#     plt.axis('off')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vlidation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 12, 32, 32])\n",
      "torch.Size([100, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "val_dataset = get_dataset(\n",
    "      val_path,\n",
    "      data_size=64,\n",
    "      sample_size=32,\n",
    "      batch_size=100,\n",
    "      num_in_channels=12,\n",
    "      compression_type=None,\n",
    "      clip_and_normalize=False,\n",
    "      clip_and_rescale=False,\n",
    "      random_crop=True,\n",
    "      center_crop=False)\n",
    "\n",
    "val_inputs, val_labels = next(iter(val_dataset))\n",
    "\n",
    "print(val_inputs.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 12, 32, 32])\n",
      "torch.Size([100, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "test_dataset = get_dataset(\n",
    "      test_path,\n",
    "      data_size=64,\n",
    "      sample_size=32,\n",
    "      batch_size=100,\n",
    "      num_in_channels=12,\n",
    "      compression_type=None,\n",
    "      clip_and_normalize=False,\n",
    "      clip_and_rescale=False,\n",
    "      random_crop=True,\n",
    "      center_crop=False)\n",
    "\n",
    "test_inputs, test_labels = next(iter(val_dataset))\n",
    "\n",
    "print(test_inputs.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=None, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=None, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=None, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './diff_models'\n",
    "gen_input_channels = 12\n",
    "disc_input_channels = 13\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    \"\"\"Sinusoidal positional embedding for time steps.\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # t: [batch] of timesteps (float or long)\n",
    "        device = t.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = t[:, None].float() * emb[None, :]  # [batch, half_dim]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        if self.dim % 2 == 1:  # if odd dimensionality\n",
    "            emb = F.pad(emb, (0, 1, 0, 0))\n",
    "        return emb  # [batch, dim]\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with optional time embedding.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.GroupNorm(num_groups=8, num_channels=in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.norm2 = nn.GroupNorm(num_groups=8, num_channels=out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.time_proj = nn.Linear(time_emb_dim, out_channels)\n",
    "        if in_channels != out_channels:\n",
    "            self.skip_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        else:\n",
    "            self.skip_conv = None\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        h = self.norm1(x)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv1(h)\n",
    "        # Add time embedding\n",
    "        if t_emb is not None:\n",
    "            time_emb = self.time_proj(F.relu(t_emb))\n",
    "            h = h + time_emb[:, :, None, None]\n",
    "        h = self.norm2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        # Skip connection\n",
    "        if self.skip_conv is not None:\n",
    "            x = self.skip_conv(x)\n",
    "        return x + h\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Multi-head self-attention layer.\"\"\"\n",
    "    def __init__(self, channels, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.norm = nn.GroupNorm(num_groups=8, num_channels=channels)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=channels, num_heads=num_heads)\n",
    "        self.proj_out = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.norm(x).view(B, C, H * W).permute(2, 0, 1)  # [HW, B, C]\n",
    "        attn_out, _ = self.attn(h, h, h)\n",
    "        attn_out = attn_out.permute(1, 2, 0).contiguous().view(B, C, H, W)\n",
    "        attn_out = self.proj_out(attn_out)\n",
    "        return x + attn_out\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downsampling block: 2 ResBlocks + Conv2d downsample.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim):\n",
    "        super().__init__()\n",
    "        self.res1 = ResidualBlock(in_channels, out_channels, time_emb_dim)\n",
    "        self.res2 = ResidualBlock(out_channels, out_channels, time_emb_dim)\n",
    "        self.downsample = nn.Conv2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        x = self.res1(x, t)\n",
    "        x = self.res2(x, t)\n",
    "        x_down = self.downsample(x)\n",
    "        return x_down, x  # return downsampled output and skip connection\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upsampling block: ConvTranspose2d upsample + 2 ResBlocks.\"\"\"\n",
    "    def __init__(self, in_channels, skip_channels, out_channels, time_emb_dim):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.res1 = ResidualBlock(out_channels + skip_channels, out_channels, time_emb_dim)\n",
    "        self.res2 = ResidualBlock(out_channels, out_channels, time_emb_dim)\n",
    "    \n",
    "    def forward(self, x, skip, t):\n",
    "        x = self.upsample(x)                # Upsample\n",
    "        x = torch.cat([x, skip], dim=1)    # Concatenate skip connection\n",
    "        x = self.res1(x, t)\n",
    "        x = self.res2(x, t)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net model for conditional diffusion (13->1 channels).\"\"\"\n",
    "    def __init__(self, in_channels=13, base_channels=64, channel_mults=(1,2,4,8), time_emb_dim=256):\n",
    "        super().__init__()\n",
    "        # Time embedding\n",
    "        self.time_emb = SinusoidalPosEmb(time_emb_dim // 2)\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(time_emb_dim // 2, time_emb_dim), nn.ReLU(),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim)\n",
    "        )\n",
    "        # Initial convolution\n",
    "        self.init_conv = nn.Conv2d(in_channels, base_channels * channel_mults[0], kernel_size=3, padding=1)\n",
    "        # Downsample blocks\n",
    "        self.down1 = Down(base_channels * channel_mults[0], base_channels * channel_mults[1], time_emb_dim)\n",
    "        self.down2 = Down(base_channels * channel_mults[1], base_channels * channel_mults[2], time_emb_dim)\n",
    "        self.attn_down2 = SelfAttention(base_channels * channel_mults[2])\n",
    "        self.down3 = Down(base_channels * channel_mults[2], base_channels * channel_mults[3], time_emb_dim)\n",
    "        # Bottleneck\n",
    "        self.mid_res1 = ResidualBlock(base_channels * channel_mults[3], base_channels * channel_mults[3], time_emb_dim)\n",
    "        self.mid_attn = SelfAttention(base_channels * channel_mults[3])\n",
    "        self.mid_res2 = ResidualBlock(base_channels * channel_mults[3], base_channels * channel_mults[3], time_emb_dim)\n",
    "        # Upsample blocks\n",
    "        self.up3 = Up(base_channels * channel_mults[3], base_channels * channel_mults[3], base_channels * channel_mults[2], time_emb_dim)\n",
    "        self.up2 = Up(base_channels * channel_mults[2], base_channels * channel_mults[2], base_channels * channel_mults[1], time_emb_dim)\n",
    "        self.up1 = Up(base_channels * channel_mults[1], base_channels * channel_mults[1], base_channels * channel_mults[0], time_emb_dim)\n",
    "        # Final conv to one channel output\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.GroupNorm(num_groups=8, num_channels=base_channels * channel_mults[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(base_channels * channel_mults[0], 1, kernel_size=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # x: [B,13,32,32], t: [B] timesteps\n",
    "        t_emb = self.time_emb(t)          # [B, time_emb_dim//2]\n",
    "        t_emb = self.time_mlp(t_emb)      # [B, time_emb_dim]\n",
    "        x = self.init_conv(x)            # [B, base, 32,32]\n",
    "        x1, skip1 = self.down1(x, t_emb)   # [B, C1, 16,16], skip1 [B, C1,16,16]\n",
    "        x2, skip2 = self.down2(x1, t_emb)  # [B, C2, 8,8], skip2 [B, C2,8,8]\n",
    "        x2 = self.attn_down2(x2)          # Self-attention at 8x8\n",
    "        x3, skip3 = self.down3(x2, t_emb)  # [B, C3, 4,4], skip3 [B, C3,4,4]\n",
    "        x_mid = self.mid_res1(x3, t_emb)\n",
    "        x_mid = self.mid_attn(x_mid)       # Self-attention at 4x4\n",
    "        x_mid = self.mid_res2(x_mid, t_emb)\n",
    "        x = self.up3(x_mid, skip3, t_emb)  # [B, C2, 8,8]\n",
    "        x = self.up2(x, skip2, t_emb)      # [B, C1, 16,16]\n",
    "        x = self.up1(x, skip1, t_emb)      # [B, base, 32,32]\n",
    "        x = self.final_conv(x)            # [B, 1, 32,32]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  Train Loss: 1.0006 | Val Loss: 1.0010\n",
      "  ▶️ Validation improved. \n",
      "Epoch 2/200\n",
      "  Train Loss: 1.0003 | Val Loss: 1.0006\n",
      "  ▶️ Validation improved. \n",
      "Epoch 3/200\n",
      "  Train Loss: 1.0005 | Val Loss: 0.9980\n",
      "  ▶️ Validation improved. \n",
      "Epoch 4/200\n",
      "  Train Loss: 1.0001 | Val Loss: 0.9999\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 5/200\n",
      "  Train Loss: 0.9996 | Val Loss: 0.9982\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 6/200\n",
      "  Train Loss: 0.9992 | Val Loss: 0.9980\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 7/200\n",
      "  Train Loss: 0.9959 | Val Loss: 0.9734\n",
      "  ▶️ Validation improved. \n",
      "Epoch 8/200\n",
      "  Train Loss: 0.8043 | Val Loss: 0.5846\n",
      "  ▶️ Validation improved. \n",
      "Epoch 9/200\n",
      "  Train Loss: 0.4268 | Val Loss: 0.3207\n",
      "  ▶️ Validation improved. \n",
      "Epoch 10/200\n",
      "  Train Loss: 0.2869 | Val Loss: 0.3620\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 11/200\n",
      "  Train Loss: 0.2286 | Val Loss: 0.1886\n",
      "  ▶️ Validation improved. \n",
      "Epoch 12/200\n",
      "  Train Loss: 0.1668 | Val Loss: 0.1443\n",
      "  ▶️ Validation improved. \n",
      "Epoch 13/200\n",
      "  Train Loss: 0.1377 | Val Loss: 0.1169\n",
      "  ▶️ Validation improved. \n",
      "Epoch 14/200\n",
      "  Train Loss: 0.1282 | Val Loss: 0.1188\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 15/200\n",
      "  Train Loss: 0.1097 | Val Loss: 0.0898\n",
      "  ▶️ Validation improved. \n",
      "Epoch 16/200\n",
      "  Train Loss: 0.1016 | Val Loss: 0.0934\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 17/200\n",
      "  Train Loss: 0.0948 | Val Loss: 0.1083\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 18/200\n",
      "  Train Loss: 0.0892 | Val Loss: 0.0856\n",
      "  ▶️ Validation improved. \n",
      "Epoch 19/200\n",
      "  Train Loss: 0.0848 | Val Loss: 0.0710\n",
      "  ▶️ Validation improved. \n",
      "Epoch 20/200\n",
      "  Train Loss: 0.0784 | Val Loss: 0.0844\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 21/200\n",
      "  Train Loss: 0.0754 | Val Loss: 0.0600\n",
      "  ▶️ Validation improved. \n",
      "Epoch 22/200\n",
      "  Train Loss: 0.0684 | Val Loss: 0.0664\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 23/200\n",
      "  Train Loss: 0.0678 | Val Loss: 0.0617\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 24/200\n",
      "  Train Loss: 0.0683 | Val Loss: 0.0608\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 25/200\n",
      "  Train Loss: 0.0638 | Val Loss: 0.0594\n",
      "  ▶️ Validation improved. \n",
      "Epoch 26/200\n",
      "  Train Loss: 0.0614 | Val Loss: 0.0565\n",
      "  ▶️ Validation improved. \n",
      "Epoch 27/200\n",
      "  Train Loss: 0.0591 | Val Loss: 0.0495\n",
      "  ▶️ Validation improved. \n",
      "Epoch 28/200\n",
      "  Train Loss: 0.0853 | Val Loss: 0.0596\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 29/200\n",
      "  Train Loss: 0.0567 | Val Loss: 0.0581\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 30/200\n",
      "  Train Loss: 0.0568 | Val Loss: 0.0507\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 31/200\n",
      "  Train Loss: 0.0550 | Val Loss: 0.0666\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 32/200\n",
      "  Train Loss: 0.0530 | Val Loss: 0.0642\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 33/200\n",
      "  Train Loss: 0.0521 | Val Loss: 0.0570\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 34/200\n",
      "  Train Loss: 0.0519 | Val Loss: 0.0515\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 35/200\n",
      "  Train Loss: 0.0502 | Val Loss: 0.0521\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 36/200\n",
      "  Train Loss: 0.0480 | Val Loss: 0.0468\n",
      "  ▶️ Validation improved. \n",
      "Epoch 37/200\n",
      "  Train Loss: 0.0449 | Val Loss: 0.0422\n",
      "  ▶️ Validation improved. \n",
      "Epoch 38/200\n",
      "  Train Loss: 0.0461 | Val Loss: 0.0445\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 39/200\n",
      "  Train Loss: 0.0458 | Val Loss: 0.0398\n",
      "  ▶️ Validation improved. \n",
      "Epoch 40/200\n",
      "  Train Loss: 0.0461 | Val Loss: 0.0394\n",
      "  ▶️ Validation improved. \n",
      "Epoch 41/200\n",
      "  Train Loss: 0.0437 | Val Loss: 0.0406\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 42/200\n",
      "  Train Loss: 0.0458 | Val Loss: 0.0442\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 43/200\n",
      "  Train Loss: 0.0453 | Val Loss: 0.0412\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 44/200\n",
      "  Train Loss: 0.0444 | Val Loss: 0.0405\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 45/200\n",
      "  Train Loss: 0.0414 | Val Loss: 0.0413\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 46/200\n",
      "  Train Loss: 0.0433 | Val Loss: 0.0465\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 47/200\n",
      "  Train Loss: 0.0393 | Val Loss: 0.0349\n",
      "  ▶️ Validation improved. \n",
      "Epoch 48/200\n",
      "  Train Loss: 0.0413 | Val Loss: 0.0362\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 49/200\n",
      "  Train Loss: 0.0411 | Val Loss: 0.0347\n",
      "  ▶️ Validation improved. \n",
      "Epoch 50/200\n",
      "  Train Loss: 0.0390 | Val Loss: 0.0462\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 51/200\n",
      "  Train Loss: 0.0377 | Val Loss: 0.0355\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 52/200\n",
      "  Train Loss: 0.0391 | Val Loss: 0.0390\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 53/200\n",
      "  Train Loss: 0.0414 | Val Loss: 0.0392\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 54/200\n",
      "  Train Loss: 0.0367 | Val Loss: 0.0334\n",
      "  ▶️ Validation improved. \n",
      "Epoch 55/200\n",
      "  Train Loss: 0.0371 | Val Loss: 0.0406\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 56/200\n",
      "  Train Loss: 0.0381 | Val Loss: 0.0389\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 57/200\n",
      "  Train Loss: 0.0372 | Val Loss: 0.0377\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 58/200\n",
      "  Train Loss: 0.0367 | Val Loss: 0.0283\n",
      "  ▶️ Validation improved. \n",
      "Epoch 59/200\n",
      "  Train Loss: 0.0369 | Val Loss: 0.0377\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 60/200\n",
      "  Train Loss: 0.0354 | Val Loss: 0.0334\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 61/200\n",
      "  Train Loss: 0.0430 | Val Loss: 0.1831\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 62/200\n",
      "  Train Loss: 0.1042 | Val Loss: 0.0377\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 63/200\n",
      "  Train Loss: 0.0363 | Val Loss: 0.0395\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 64/200\n",
      "  Train Loss: 0.0357 | Val Loss: 0.0293\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 65/200\n",
      "  Train Loss: 0.0345 | Val Loss: 0.0385\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 66/200\n",
      "  Train Loss: 0.0334 | Val Loss: 0.0313\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 67/200\n",
      "  Train Loss: 0.0343 | Val Loss: 0.0596\n",
      "  No improvement for 9 epoch(s).\n",
      "Epoch 68/200\n",
      "  Train Loss: 0.0355 | Val Loss: 0.0323\n",
      "  No improvement for 10 epoch(s).\n",
      "Epoch 69/200\n",
      "  Train Loss: 0.0338 | Val Loss: 0.0289\n",
      "  No improvement for 11 epoch(s).\n",
      "Epoch 70/200\n",
      "  Train Loss: 0.0345 | Val Loss: 0.0318\n",
      "  No improvement for 12 epoch(s).\n",
      "Epoch 71/200\n",
      "  Train Loss: 0.0331 | Val Loss: 0.0309\n",
      "  No improvement for 13 epoch(s).\n",
      "Epoch 72/200\n",
      "  Train Loss: 0.0337 | Val Loss: 0.0306\n",
      "  No improvement for 14 epoch(s).\n",
      "Epoch 73/200\n",
      "  Train Loss: 0.0336 | Val Loss: 0.0298\n",
      "  No improvement for 15 epoch(s).\n",
      "Epoch 74/200\n",
      "  Train Loss: 0.0338 | Val Loss: 0.0376\n",
      "  No improvement for 16 epoch(s).\n",
      "Epoch 75/200\n",
      "  Train Loss: 0.0323 | Val Loss: 0.0311\n",
      "  No improvement for 17 epoch(s).\n",
      "Epoch 76/200\n",
      "  Train Loss: 0.0310 | Val Loss: 0.0319\n",
      "  No improvement for 18 epoch(s).\n",
      "Epoch 77/200\n",
      "  Train Loss: 0.0314 | Val Loss: 0.0305\n",
      "  No improvement for 19 epoch(s).\n",
      "Epoch 78/200\n",
      "  Train Loss: 0.0331 | Val Loss: 0.0316\n",
      "  No improvement for 20 epoch(s).\n",
      "Epoch 79/200\n",
      "  Train Loss: 0.0320 | Val Loss: 0.0301\n",
      "  No improvement for 21 epoch(s).\n",
      "Epoch 80/200\n",
      "  Train Loss: 0.0298 | Val Loss: 0.0337\n",
      "  No improvement for 22 epoch(s).\n",
      "Epoch 81/200\n",
      "  Train Loss: 0.0315 | Val Loss: 0.0274\n",
      "  ▶️ Validation improved. \n",
      "Epoch 82/200\n",
      "  Train Loss: 0.0308 | Val Loss: 0.0311\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 83/200\n",
      "  Train Loss: 0.0318 | Val Loss: 0.0270\n",
      "  ▶️ Validation improved. \n",
      "Epoch 84/200\n",
      "  Train Loss: 0.0300 | Val Loss: 0.0283\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 85/200\n",
      "  Train Loss: 0.0310 | Val Loss: 0.0321\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 86/200\n",
      "  Train Loss: 0.0286 | Val Loss: 0.0245\n",
      "  ▶️ Validation improved. \n",
      "Epoch 87/200\n",
      "  Train Loss: 0.0329 | Val Loss: 0.0269\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 88/200\n",
      "  Train Loss: 0.0276 | Val Loss: 0.0234\n",
      "  ▶️ Validation improved. \n",
      "Epoch 89/200\n",
      "  Train Loss: 0.0298 | Val Loss: 0.0240\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 90/200\n",
      "  Train Loss: 0.0313 | Val Loss: 0.0238\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 91/200\n",
      "  Train Loss: 0.0305 | Val Loss: 0.0262\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 92/200\n",
      "  Train Loss: 0.0301 | Val Loss: 0.0293\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 93/200\n",
      "  Train Loss: 0.0289 | Val Loss: 0.0248\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 94/200\n",
      "  Train Loss: 0.0292 | Val Loss: 0.0303\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 95/200\n",
      "  Train Loss: 0.0282 | Val Loss: 0.0244\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 96/200\n",
      "  Train Loss: 0.0307 | Val Loss: 0.0255\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 97/200\n",
      "  Train Loss: 0.0292 | Val Loss: 0.0342\n",
      "  No improvement for 9 epoch(s).\n",
      "Epoch 98/200\n",
      "  Train Loss: 0.0275 | Val Loss: 0.0298\n",
      "  No improvement for 10 epoch(s).\n",
      "Epoch 99/200\n",
      "  Train Loss: 0.0275 | Val Loss: 0.0245\n",
      "  No improvement for 11 epoch(s).\n",
      "Epoch 100/200\n",
      "  Train Loss: 0.0269 | Val Loss: 0.0244\n",
      "  No improvement for 12 epoch(s).\n",
      "Epoch 101/200\n",
      "  Train Loss: 0.0297 | Val Loss: 0.0235\n",
      "  No improvement for 13 epoch(s).\n",
      "Epoch 102/200\n",
      "  Train Loss: 0.0248 | Val Loss: 0.0212\n",
      "  ▶️ Validation improved. \n",
      "Epoch 103/200\n",
      "  Train Loss: 0.0270 | Val Loss: 0.0243\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 104/200\n",
      "  Train Loss: 0.0257 | Val Loss: 0.0266\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 105/200\n",
      "  Train Loss: 0.0278 | Val Loss: 0.0236\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 106/200\n",
      "  Train Loss: 0.0298 | Val Loss: 0.0286\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 107/200\n",
      "  Train Loss: 0.0271 | Val Loss: 0.0291\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 108/200\n",
      "  Train Loss: 0.0239 | Val Loss: 0.0228\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 109/200\n",
      "  Train Loss: 0.0267 | Val Loss: 0.0228\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 110/200\n",
      "  Train Loss: 0.0264 | Val Loss: 0.0227\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 111/200\n",
      "  Train Loss: 0.0243 | Val Loss: 0.0208\n",
      "  ▶️ Validation improved. \n",
      "Epoch 112/200\n",
      "  Train Loss: 0.0310 | Val Loss: 0.0259\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 113/200\n",
      "  Train Loss: 0.0249 | Val Loss: 0.0282\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 114/200\n",
      "  Train Loss: 0.0264 | Val Loss: 0.0250\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 115/200\n",
      "  Train Loss: 0.0276 | Val Loss: 0.0430\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 116/200\n",
      "  Train Loss: 0.0285 | Val Loss: 0.0234\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 117/200\n",
      "  Train Loss: 0.0271 | Val Loss: 0.0238\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 118/200\n",
      "  Train Loss: 0.0260 | Val Loss: 0.0220\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 119/200\n",
      "  Train Loss: 0.0265 | Val Loss: 0.0249\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 120/200\n",
      "  Train Loss: 0.0263 | Val Loss: 0.0258\n",
      "  No improvement for 9 epoch(s).\n",
      "Epoch 121/200\n",
      "  Train Loss: 0.0252 | Val Loss: 0.0217\n",
      "  No improvement for 10 epoch(s).\n",
      "Epoch 122/200\n",
      "  Train Loss: 0.0227 | Val Loss: 0.0232\n",
      "  No improvement for 11 epoch(s).\n",
      "Epoch 123/200\n",
      "  Train Loss: 0.0256 | Val Loss: 0.0271\n",
      "  No improvement for 12 epoch(s).\n",
      "Epoch 124/200\n",
      "  Train Loss: 0.0236 | Val Loss: 0.0215\n",
      "  No improvement for 13 epoch(s).\n",
      "Epoch 125/200\n",
      "  Train Loss: 0.0236 | Val Loss: 0.0246\n",
      "  No improvement for 14 epoch(s).\n",
      "Epoch 126/200\n",
      "  Train Loss: 0.0225 | Val Loss: 0.0174\n",
      "  ▶️ Validation improved. \n",
      "Epoch 127/200\n",
      "  Train Loss: 0.0233 | Val Loss: 0.0213\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 128/200\n",
      "  Train Loss: 0.0256 | Val Loss: 0.0208\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 129/200\n",
      "  Train Loss: 0.0230 | Val Loss: 0.0192\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 130/200\n",
      "  Train Loss: 0.0246 | Val Loss: 0.0224\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 131/200\n",
      "  Train Loss: 0.0256 | Val Loss: 0.0195\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 132/200\n",
      "  Train Loss: 0.0226 | Val Loss: 0.0313\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 133/200\n",
      "  Train Loss: 0.0238 | Val Loss: 0.0254\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 134/200\n",
      "  Train Loss: 0.0223 | Val Loss: 0.0207\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 135/200\n",
      "  Train Loss: 0.0252 | Val Loss: 0.0247\n",
      "  No improvement for 9 epoch(s).\n",
      "Epoch 136/200\n",
      "  Train Loss: 0.0225 | Val Loss: 0.0178\n",
      "  No improvement for 10 epoch(s).\n",
      "Epoch 137/200\n",
      "  Train Loss: 0.0223 | Val Loss: 0.0208\n",
      "  No improvement for 11 epoch(s).\n",
      "Epoch 138/200\n",
      "  Train Loss: 0.0227 | Val Loss: 0.0299\n",
      "  No improvement for 12 epoch(s).\n",
      "Epoch 139/200\n",
      "  Train Loss: 0.0243 | Val Loss: 0.0182\n",
      "  No improvement for 13 epoch(s).\n",
      "Epoch 140/200\n",
      "  Train Loss: 0.0227 | Val Loss: 0.0183\n",
      "  No improvement for 14 epoch(s).\n",
      "Epoch 141/200\n",
      "  Train Loss: 0.0226 | Val Loss: 0.0316\n",
      "  No improvement for 15 epoch(s).\n",
      "Epoch 142/200\n",
      "  Train Loss: 0.0240 | Val Loss: 0.0222\n",
      "  No improvement for 16 epoch(s).\n",
      "Epoch 143/200\n",
      "  Train Loss: 0.0224 | Val Loss: 0.0201\n",
      "  No improvement for 17 epoch(s).\n",
      "Epoch 144/200\n",
      "  Train Loss: 0.0223 | Val Loss: 0.0185\n",
      "  No improvement for 18 epoch(s).\n",
      "Epoch 145/200\n",
      "  Train Loss: 0.0225 | Val Loss: 0.0174\n",
      "  No improvement for 19 epoch(s).\n",
      "Epoch 146/200\n",
      "  Train Loss: 0.0231 | Val Loss: 0.0257\n",
      "  No improvement for 20 epoch(s).\n",
      "Epoch 147/200\n",
      "  Train Loss: 0.0225 | Val Loss: 0.0283\n",
      "  No improvement for 21 epoch(s).\n",
      "Epoch 148/200\n",
      "  Train Loss: 0.0208 | Val Loss: 0.0175\n",
      "  No improvement for 22 epoch(s).\n",
      "Epoch 149/200\n",
      "  Train Loss: 0.0218 | Val Loss: 0.0176\n",
      "  No improvement for 23 epoch(s).\n",
      "Epoch 150/200\n",
      "  Train Loss: 0.0242 | Val Loss: 0.0189\n",
      "  No improvement for 24 epoch(s).\n",
      "Epoch 151/200\n",
      "  Train Loss: 0.0238 | Val Loss: 0.0191\n",
      "  No improvement for 25 epoch(s).\n",
      "Epoch 152/200\n",
      "  Train Loss: 0.0198 | Val Loss: 0.0186\n",
      "  No improvement for 26 epoch(s).\n",
      "Epoch 153/200\n",
      "  Train Loss: 0.0233 | Val Loss: 0.0261\n",
      "  No improvement for 27 epoch(s).\n",
      "Epoch 154/200\n",
      "  Train Loss: 0.0207 | Val Loss: 0.0199\n",
      "  No improvement for 28 epoch(s).\n",
      "Epoch 155/200\n",
      "  Train Loss: 0.0194 | Val Loss: 0.0220\n",
      "  No improvement for 29 epoch(s).\n",
      "Epoch 156/200\n",
      "  Train Loss: 0.0227 | Val Loss: 0.0174\n",
      "  No improvement for 30 epoch(s).\n",
      "Epoch 157/200\n",
      "  Train Loss: 0.0210 | Val Loss: 0.0163\n",
      "  ▶️ Validation improved. \n",
      "Epoch 158/200\n",
      "  Train Loss: 0.0199 | Val Loss: 0.0180\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 159/200\n",
      "  Train Loss: 0.0205 | Val Loss: 0.0204\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 160/200\n",
      "  Train Loss: 0.0240 | Val Loss: 0.0263\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 161/200\n",
      "  Train Loss: 0.0196 | Val Loss: 0.0170\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 162/200\n",
      "  Train Loss: 0.0209 | Val Loss: 0.0189\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 163/200\n",
      "  Train Loss: 0.0224 | Val Loss: 0.0478\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 164/200\n",
      "  Train Loss: 0.0206 | Val Loss: 0.0199\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 165/200\n",
      "  Train Loss: 0.0215 | Val Loss: 0.0190\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 166/200\n",
      "  Train Loss: 0.0209 | Val Loss: 0.0193\n",
      "  No improvement for 9 epoch(s).\n",
      "Epoch 167/200\n",
      "  Train Loss: 0.0184 | Val Loss: 0.0182\n",
      "  No improvement for 10 epoch(s).\n",
      "Epoch 168/200\n",
      "  Train Loss: 0.0215 | Val Loss: 0.0227\n",
      "  No improvement for 11 epoch(s).\n",
      "Epoch 169/200\n",
      "  Train Loss: 0.0196 | Val Loss: 0.0155\n",
      "  ▶️ Validation improved. \n",
      "Epoch 170/200\n",
      "  Train Loss: 0.0189 | Val Loss: 0.0197\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 171/200\n",
      "  Train Loss: 0.0214 | Val Loss: 0.0149\n",
      "  ▶️ Validation improved. \n",
      "Epoch 172/200\n",
      "  Train Loss: 0.0190 | Val Loss: 0.0182\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 173/200\n",
      "  Train Loss: 0.0210 | Val Loss: 0.0187\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 174/200\n",
      "  Train Loss: 0.0180 | Val Loss: 0.0211\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 175/200\n",
      "  Train Loss: 0.0194 | Val Loss: 0.0198\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 176/200\n",
      "  Train Loss: 0.0190 | Val Loss: 0.0185\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 177/200\n",
      "  Train Loss: 0.0186 | Val Loss: 0.0182\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 178/200\n",
      "  Train Loss: 0.0177 | Val Loss: 0.0155\n",
      "  No improvement for 7 epoch(s).\n",
      "Epoch 179/200\n",
      "  Train Loss: 0.0202 | Val Loss: 0.0153\n",
      "  No improvement for 8 epoch(s).\n",
      "Epoch 180/200\n",
      "  Train Loss: 0.0182 | Val Loss: 0.0236\n",
      "  No improvement for 9 epoch(s).\n",
      "Epoch 181/200\n",
      "  Train Loss: 0.0180 | Val Loss: 0.0168\n",
      "  No improvement for 10 epoch(s).\n",
      "Epoch 182/200\n",
      "  Train Loss: 0.0187 | Val Loss: 0.0188\n",
      "  No improvement for 11 epoch(s).\n",
      "Epoch 183/200\n",
      "  Train Loss: 0.0187 | Val Loss: 0.0186\n",
      "  No improvement for 12 epoch(s).\n",
      "Epoch 184/200\n",
      "  Train Loss: 0.0171 | Val Loss: 0.0191\n",
      "  No improvement for 13 epoch(s).\n",
      "Epoch 185/200\n",
      "  Train Loss: 0.0213 | Val Loss: 0.0151\n",
      "  No improvement for 14 epoch(s).\n",
      "Epoch 186/200\n",
      "  Train Loss: 0.0198 | Val Loss: 0.0152\n",
      "  No improvement for 15 epoch(s).\n",
      "Epoch 187/200\n",
      "  Train Loss: 0.0182 | Val Loss: 0.0215\n",
      "  No improvement for 16 epoch(s).\n",
      "Epoch 188/200\n",
      "  Train Loss: 0.0207 | Val Loss: 0.0169\n",
      "  No improvement for 17 epoch(s).\n",
      "Epoch 189/200\n",
      "  Train Loss: 0.0184 | Val Loss: 0.0138\n",
      "  ▶️ Validation improved. \n",
      "Epoch 190/200\n",
      "  Train Loss: 0.0225 | Val Loss: 0.0204\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 191/200\n",
      "  Train Loss: 0.0182 | Val Loss: 0.0176\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 192/200\n",
      "  Train Loss: 0.0187 | Val Loss: 0.0187\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 193/200\n",
      "  Train Loss: 0.0198 | Val Loss: 0.0127\n",
      "  ▶️ Validation improved. \n",
      "Epoch 194/200\n",
      "  Train Loss: 0.0191 | Val Loss: 0.0155\n",
      "  No improvement for 1 epoch(s).\n",
      "Epoch 195/200\n",
      "  Train Loss: 0.0183 | Val Loss: 0.0154\n",
      "  No improvement for 2 epoch(s).\n",
      "Epoch 196/200\n",
      "  Train Loss: 0.0190 | Val Loss: 0.0167\n",
      "  No improvement for 3 epoch(s).\n",
      "Epoch 197/200\n",
      "  Train Loss: 0.0167 | Val Loss: 0.0149\n",
      "  No improvement for 4 epoch(s).\n",
      "Epoch 198/200\n",
      "  Train Loss: 0.0178 | Val Loss: 0.0180\n",
      "  No improvement for 5 epoch(s).\n",
      "Epoch 199/200\n",
      "  Train Loss: 0.0175 | Val Loss: 0.0170\n",
      "  No improvement for 6 epoch(s).\n",
      "Epoch 200/200\n",
      "  Train Loss: 0.0171 | Val Loss: 0.0159\n",
      "  No improvement for 7 epoch(s).\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Diffusion:\n",
    "    \"\"\"Diffusion process with linear beta schedule.\"\"\"\n",
    "    def __init__(self, timesteps=1000, beta_start=1e-4, beta_end=0.02, device='cpu'):\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        betas = torch.linspace(beta_start, beta_end, timesteps, device=device)\n",
    "        self.betas = betas\n",
    "        self.alphas = 1.0 - betas\n",
    "        self.alpha_hat = torch.cumprod(self.alphas, dim=0)             # \\bar{alpha}_t\n",
    "        self.sqrt_alpha_hat = torch.sqrt(self.alpha_hat)               # sqrt(\\bar{alpha}_t)\n",
    "        self.sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat) # sqrt(1-\\bar{alpha}_t)\n",
    "    \n",
    "    def q_sample(self, x_start, t):\n",
    "        \"\"\"Sample q(x_t | x_0): add noise to x_start for timestep t.\"\"\"\n",
    "        noise = torch.randn_like(x_start)\n",
    "        # Expand scalars to batch dims\n",
    "        sqrt_alpha_hat_t = self.sqrt_alpha_hat[t].view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_hat_t = self.sqrt_one_minus_alpha_hat[t].view(-1, 1, 1, 1)\n",
    "        x_t = sqrt_alpha_hat_t * x_start + sqrt_one_minus_alpha_hat_t * noise\n",
    "        return x_t, noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, cond, steps=None, guidance_scale=1.0):\n",
    "        \"\"\"Generate samples given conditional input using reverse diffusion.\"\"\"\n",
    "        if steps is None:\n",
    "            steps = self.timesteps\n",
    "        B = cond.shape[0]\n",
    "        x = torch.randn((B, 1, cond.shape[2], cond.shape[3]), device=self.device)  # Start from noise\n",
    "        for t in reversed(range(steps)):\n",
    "            t_batch = torch.full((B,), t, dtype=torch.long, device=self.device)\n",
    "            # Prepare inputs for conditional and unconditional (zeros) predictions\n",
    "            x_in_cond = torch.cat([cond, x], dim=1)        # [B, 13, 32,32]\n",
    "            x_in_uncond = torch.cat([torch.zeros_like(cond), x], dim=1)\n",
    "            noise_cond = model(x_in_cond, t_batch)         # Predicted noise (conditional)\n",
    "            noise_uncond = model(x_in_uncond, t_batch)     # Predicted noise (unconditional)\n",
    "            # Classifier-free guidance\n",
    "            noise_pred = noise_uncond + guidance_scale * (noise_cond - noise_uncond)\n",
    "            # Compute x0 estimate\n",
    "            alpha_hat_t = self.alpha_hat[t]\n",
    "            sqrt_alpha_hat_t = self.sqrt_alpha_hat[t]\n",
    "            if t > 0:\n",
    "                alpha_hat_prev = self.alpha_hat[t-1]\n",
    "                sqrt_alpha_hat_prev = torch.sqrt(alpha_hat_prev)\n",
    "            else:\n",
    "                alpha_hat_prev = torch.tensor(1.0, device=self.device)\n",
    "                sqrt_alpha_hat_prev = torch.tensor(1.0, device=self.device)\n",
    "            x0_pred = (x - (self.sqrt_one_minus_alpha_hat[t] * noise_pred)) / sqrt_alpha_hat_t\n",
    "            # Compute x_{t-1} (add noise except for final step)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "                x = sqrt_alpha_hat_prev * x0_pred + torch.sqrt(1 - alpha_hat_prev) * noise\n",
    "            else:\n",
    "                x = x0_pred\n",
    "        return x  # [B,1,32,32]\n",
    "\n",
    "def train_with_early_stopping(\n",
    "    model,\n",
    "    diffusion,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    lr=1e-4,\n",
    "    num_epochs=200,\n",
    "    patience=50,\n",
    "    folder_path='./checkpoints',\n",
    "    device='cpu'\n",
    "):\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Optimizer & tracking\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    best_model_path = None\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # ---------- Train ----------\n",
    "        model.train()\n",
    "        train_loss_sum = 0.0\n",
    "        for features, target in train_loader:\n",
    "            features = features.to(device)        # [B,12,32,32]\n",
    "            target   = target.to(device)         # [B,1,32,32]\n",
    "            B = features.size(0)\n",
    "\n",
    "            # 1) 랜덤 timestep 선택, noisy sample 생성\n",
    "            t = torch.randint(0, diffusion.timesteps, (B,), device=device)\n",
    "            x_noisy, noise = diffusion.q_sample(target, t)\n",
    "\n",
    "            # 2) 모델 입력: [B, 13, 32,32]\n",
    "            inp = torch.cat([features, x_noisy], dim=1)\n",
    "            pred_noise = model(inp, t)\n",
    "\n",
    "            # 3) 손실 계산 및 역전파\n",
    "            loss = F.mse_loss(pred_noise, noise)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "        train_avg_loss = train_loss_sum / len(train_loader)\n",
    "\n",
    "        # ---------- Validation ----------\n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for features, target in val_loader:\n",
    "                features = features.to(device)\n",
    "                target   = target.to(device)\n",
    "                B = features.size(0)\n",
    "\n",
    "                t = torch.randint(0, diffusion.timesteps, (B,), device=device)\n",
    "                x_noisy, noise = diffusion.q_sample(target, t)\n",
    "                inp = torch.cat([features, x_noisy], dim=1)\n",
    "                pred_noise = model(inp, t)\n",
    "                loss = F.mse_loss(pred_noise, noise)\n",
    "                val_loss_sum += loss.item()\n",
    "\n",
    "        val_avg_loss = val_loss_sum / len(val_loader)\n",
    "\n",
    "        # ---------- Logging ----------\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        print(f\"  Train Loss: {train_avg_loss:.4f} | Val Loss: {val_avg_loss:.4f}\")\n",
    "\n",
    "        # ---------- Early Stopping & Checkpoint ----------\n",
    "        if val_avg_loss < best_val_loss:\n",
    "            best_val_loss = val_avg_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            best_model_path = os.path.join(\n",
    "                folder_path,\n",
    "                f\"best_diffusion_{best_val_loss:.4f}_{timestamp}.pth\"\n",
    "            )\n",
    "            \n",
    "            print(f\"  ▶️ Validation improved. \")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"⏹️ Early stopping triggered (patience={patience}).\")\n",
    "            break\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    return best_model_path, best_model_state\n",
    "\n",
    "\n",
    "# Example usage (assuming .npy dataset files exist):\n",
    "# dataset = WildfireDataset('features.npy', 'targets.npy')\n",
    "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet().to(device)\n",
    "diffusion = Diffusion(timesteps=1000, device=device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "path, state = train_with_early_stopping(model, diffusion, train_loader, val_loader, device=device)\n",
    "#\n",
    "# # Sampling example after training:\n",
    "#model.eval()\n",
    "# sample_cond = torch.randn(1, 12, 32, 32).to(device)  # example condition\n",
    "# generated = diffusion.sample(model, sample_cond, steps=1000, guidance_scale=2.0)\n",
    "# # 'generated' is a [1,1,32,32] predicted wildfire spread map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved to ./checkpoints\\best_diffusion_0.0127_20250428_040350.pth\n"
     ]
    }
   ],
   "source": [
    "# save the best model\n",
    "os.makedirs('./diff_models/models', exist_ok=True)\n",
    "if state is not None:\n",
    "    torch.save(state, path)\n",
    "    print(f\"Best model saved to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "** Test Results **\n",
      "Dice Coefficient: 0.0650\n",
      "IoU: 0.0336\n",
      "Recall: 0.0723\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_diffusion_model(\n",
    "    model,\n",
    "    diffusion,\n",
    "    test_loader,\n",
    "    checkpoint_path,\n",
    "    device='cpu',\n",
    "    guidance_scale=1.0,\n",
    "    sample_steps=1000,\n",
    "    bin_thresh=0.5\n",
    "):\n",
    "    \"\"\"\n",
    "    - model: UNet diffusion 모델\n",
    "    - diffusion: Diffusion 인스턴스\n",
    "    - test_loader: DataLoader for test set\n",
    "    - checkpoint_path: best .pth 경로\n",
    "    - guidance_scale, sample_steps: reverse diffusion 파라미터\n",
    "    - bin_thresh: 이진화 임계값\n",
    "    \"\"\"\n",
    "    # 1) 모델 로드 & 평가 모드\n",
    "    state_dict = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    preds_all = []\n",
    "    trues_all = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, target in test_loader:\n",
    "            features = features.to(device)   # [B,12,32,32]\n",
    "            target   = target.to(device)     # [B,1,32,32]\n",
    "\n",
    "            # 2) reverse diffusion으로 예측 맵 생성\n",
    "            generated = diffusion.sample(\n",
    "                model=model,\n",
    "                cond=features,\n",
    "                steps=sample_steps,\n",
    "                guidance_scale=guidance_scale\n",
    "            )  # [B,1,32,32]\n",
    "\n",
    "            # 3) CPU로 가져와 numpy 변환\n",
    "            preds_all.append(generated.detach().cpu().numpy())\n",
    "            trues_all.append(target.detach().cpu().numpy())\n",
    "\n",
    "    # 4) 배치 합치기\n",
    "    preds = np.concatenate(preds_all, axis=0)  # [N,1,32,32]\n",
    "    trues = np.concatenate(trues_all, axis=0)\n",
    "\n",
    "    # 5) (N,1,32,32) → (N,32,32)\n",
    "    if preds.ndim == 4 and preds.shape[1] == 1:\n",
    "        preds = preds.squeeze(1)\n",
    "        trues = trues.squeeze(1)\n",
    "\n",
    "    # 6) 이진화\n",
    "    preds_bin = (preds > bin_thresh).astype(np.uint8)\n",
    "    trues_bin = trues.astype(np.uint8)\n",
    "\n",
    "    # 7) 평탄화\n",
    "    preds_flat = preds_bin.flatten()\n",
    "    trues_flat = trues_bin.flatten()\n",
    "\n",
    "    # 8) TP, FP, FN 계산\n",
    "    tp = np.logical_and(preds_flat == 1, trues_flat == 1).sum()\n",
    "    fp = np.logical_and(preds_flat == 1, trues_flat == 0).sum()\n",
    "    fn = np.logical_and(preds_flat == 0, trues_flat == 1).sum()\n",
    "\n",
    "    smooth = 1e-6\n",
    "    dice   = (2 * tp + smooth) / (2 * tp + fp + fn + smooth)\n",
    "    iou    = (tp + smooth) / (tp + fp + fn + smooth)\n",
    "    recall = tp / (tp + fn + smooth)\n",
    "\n",
    "    metrics = {\n",
    "        'Dice Coefficient': dice,\n",
    "        'IoU': iou,\n",
    "        'Recall': recall\n",
    "    }\n",
    "\n",
    "    # 9) 결과 출력\n",
    "    print(\"\\n** Test Results **\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    return metrics, preds, trues\n",
    "\n",
    "\n",
    "metrics, preds, trues = evaluate_diffusion_model(\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    test_loader=test_loader,\n",
    "    checkpoint_path=path,\n",
    "    device=device,\n",
    "    guidance_scale=2.0,\n",
    "    sample_steps=500,\n",
    "    bin_thresh=0.5\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, lab = next(iter(test_loader))\n",
    "pred = generator(img.to(device))\n",
    "tensor_np = pred[2][0].detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(tensor_np, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor_np = lab[1][0].detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(tensor_np, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchfix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
